{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, HfArgumentParser, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
    "\n",
    "from peft import AutoPeftModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBREDDITS = [\n",
    "    \"askculinary\",\n",
    "    \"askhr\",\n",
    "    \"askdocs\",\n",
    "    \"askanthropology\",\n",
    "    \"asksciencefiction\",\n",
    "    \"askacademia\",\n",
    "    \"askengineers\",\n",
    "    \"legaladvice\",\n",
    "    \"explainlikeimfive\",\n",
    "    \"askbaking\",\n",
    "    \"askphysics\",\n",
    "    \"askscience\",\n",
    "    \"askphilosophy\",\n",
    "    \"askvet\",\n",
    "    \"changemyview\",\n",
    "    \"askcarguys\",\n",
    "    \"askhistorians\",\n",
    "    \"asksocialscience\",\n",
    "]\n",
    "\n",
    "SUBREDDITS_NORMVIO = [\"askphilosophy\", \"changemyview\", \"explainlikeimfive\", \"legaladvice\"]\n",
    "\n",
    "ANTHROPIC = [\n",
    "    \"anthropic_helpful\",\n",
    "    \"anthropic_harmful\",\n",
    "][:1]\n",
    "\n",
    "SUBREDDIT2DESCRIPTION = {\n",
    "    \"askculinary\" : \"/r/AskCulinary provides expert guidance for your specific cooking problems to help people of all skill levels become better cooks, to increase understanding of cooking, and to share valuable culinary knowledge.\",\n",
    "    \"askhr\" : \"A place for employees to ask questions about compensation, benefits, harassment, discrimination, legal, and ethical issues in the workplace.\",\n",
    "    \"askdocs\" : \"Having a medical issue? Ask a doctor or medical professional on Reddit! All flaired medical professionals on this subreddit are verified by the mods.\",\n",
    "    \"askanthropology\" : \"Have you ever wanted to know why humans have been so successful as a species? How societies function without governments, laws, or money? What life was like ten thousand years ago? This is the place to ask!\",\n",
    "    \"asksciencefiction\" : \"**It's like Ask Science, but all questions and answers are written with answers gleaned from the universe itself.** Use in-universe knowledge, rules, and common sense to answer the questions. Or as **fanlore.org** calls it [Watsonian, not a Doylist point of view](http://fanlore.org/wiki/Watsonian_vs._Doylist)\",\n",
    "    \"askacademia\" : \"This subreddit is for discussing academic life, and for asking questions directed towards people involved in academia, (both science and humanities).\",\n",
    "    \"askengineers\" : \"Engineers apply the knowledge of math & science to design and manufacture maintainable systems used to solve specific problems. AskEngineers is a forum for questions about the technologies, standards, and processes used to design & build these systems, as well as for questions about the engineering profession and its many disciplines.\",\n",
    "    \"legaladvice\" : \"A place to ask simple legal questions, and to have legal concepts explained.\",\n",
    "    \"explainlikeimfive\" : \"Explain Like I'm Five is the best forum and archive on the internet for layperson-friendly explanations. Don't Panic!\",\n",
    "    \"askbaking\" : \"Welcome to /r/AskBaking! This subreddit is devoted to the discussion of baking, the questions that arise during the process, and requests for critiques or comments on your work!\",\n",
    "    \"askphysics\" : \"A subreddit to draw simple physics questions away from /r/physics. Ask away.\",\n",
    "    \"askscience\" : \"Ask a science question, get a science answer.\",\n",
    "    \"askphilosophy\" : \"/r/askphilosophy aims to provide serious, well-researched answers to philosophical questions.\",\n",
    "    \"askvet\" : \"A place where you can ask veterinary medicine related questions and get advice from veterinary professionals.\",\n",
    "    \"changemyview\" : \"A place to post an opinion you accept may be flawed, in an effort to understand other perspectives on the issue. Enter with a mindset for conversation, not debate.\",\n",
    "    \"askcarguys\" : \"This is a subreddit for automotive related questions.\",\n",
    "    \"askhistorians\" : \"The Portal for Public History. Please read the rules before participating, as we remove all comments which break the rules. Answers must be in-depth and comprehensive, or they will be removed.\",\n",
    "    \"asksocialscience\" : \"The goal of AskSocialScience is to provide great answers to social science questions, based on solid theory, practice, and research.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014856100082397461,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b020a64f844a5b81965ab6c2c39faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## load finetuned models\n",
    "# model_name = \"../../../../llama/hf_model-7B/\"\n",
    "#model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "device=0\n",
    "if not torch.cuda.is_available():\n",
    "    device=\"cpu\"  \n",
    "\n",
    "model_names = {\"plain_all\": {}, \"subredditname_all\": {}, \"subredditname_askphysics\": {}, \"subredditname_explainlikeimfive\": {}, \"contextualized_all\": {}}\n",
    "\n",
    "# plain_all\n",
    "model_names[\"plain_all\"][\"sft\"] = \"/projects/tir6/general/sachink/personalized-LM/2023/models/0923-newreddit/sft/llama-7B_plain_all/final_checkpoint\"\n",
    "model_names[\"plain_all\"][\"dpo\"] = \"/pprojects/tir6/general/sachink/personalized-LM/2023/models/0923/dpo/llama-7B_plain_all/\"\n",
    "model_names[\"plain_all\"][\"ppo\"] = \"/projects/tir5/users/sachink/personalized-LM/0923/rlhf/llama-se-rl-finetune-128-8-8-1.4e-5_adam_plain_allstep_400\"\n",
    "# subredditname_all\n",
    "model_names[\"subredditname_all\"][\"sft\"] = \"/projects/tir6/general/sachink/personalized-LM/2023/models/0923-newreddit/sft/llama-7B_subredditname_all/final_checkpoint\"\n",
    "model_names[\"subredditname_all\"][\"dpo\"] = \"/pprojects/tir6/general/sachink/personalized-LM/2023/models/0923/dpo/llama-7B_subredditname_all/\"\n",
    "model_names[\"subredditname_all\"][\"ppo\"] = \"/projects/tir5/users/sachink/personalized-LM/0923/rlhf/llama-se-rl-finetune-128-8-8-1.4e-5_adam_subredditname_allstep_400\"\n",
    "# subredditname_askphysics\n",
    "model_names[\"subredditname_askphysics\"][\"sft\"] = \"/projects/tir6/general/sachink/personalized-LM/2023/models/0923-newreddit/sft/llama-7B_subredditname_askphysics/final_checkpoint\"\n",
    "model_names[\"subredditname_askphysics\"][\"dpo\"] = \"/pprojects/tir6/general/sachink/personalized-LM/2023/models/0923/dpo/llama-7B_subredditname_askphysics/\"\n",
    "model_names[\"subredditname_askphysics\"][\"ppo\"] = \"/projects/tir5/users/sachink/personalized-LM/0923/rlhf/llama-se-rl-finetune-128-8-8-1.4e-5_adam_subredditname_askphysicsstep_400\"\n",
    "# subredditname_explainlikeimfive \n",
    "model_names[\"subredditname_explainlikeimfive\"][\"sft\"] = \"/projects/tir6/general/sachink/personalized-LM/2023/models/0923-newreddit/sft/llama-7B_subredditname_explainlikeimfive/final_checkpoint\"\n",
    "model_names[\"subredditname_explainlikeimfive\"][\"dpo\"] = \"/pprojects/tir6/general/sachink/personalized-LM/2023/models/0923/dpo/llama-7B_subredditname_explainlikeimfive/\"\n",
    "model_names[\"subredditname_explainlikeimfive\"][\"ppo\"] = \"/projects/tir5/users/sachink/personalized-LM/0923/rlhf/llama-se-rl-finetune-128-8-8-1.4e-5_adam_subredditname_explainlikeimfivestep_400\"\n",
    "# contextualized_all\n",
    "model_names[\"contextualized_all\"][\"sft\"] = \"/projects/tir6/general/sachink/personalized-LM/2023/models/0923-newreddit/sft/llama-7B_contextualized_all/final_checkpoint\"\n",
    "model_names[\"contextualized_all\"][\"dpo\"] = \"/pprojects/tir6/general/sachink/personalized-LM/2023/models/0923/dpo/llama-7B_contextualized_all/\"\n",
    "model_names[\"contextualized_all\"][\"ppo\"] = \"/projects/tir5/users/sachink/personalized-LM/0923/rlhf/llama-se-rl-finetune-128-8-8-1.4e-5_adam_contextualized_allstep_400\"\n",
    "\n",
    "instrtype = \"subredditname\"\n",
    "subset = \"all\"\n",
    "algorithm = \"sft\"\n",
    "\n",
    "model_name = model_names[f'{instrtype}_{subset}'][f\"{algorithm}\"]\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(model_name, load_in_8bit=True)    \n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "\n",
    "generation_kwargs = {\"top_k\": 0.0, \"top_p\": 0.95, \"do_sample\": True, \"eos_token_id\": -1}\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoPeftModelForCausalLM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# subredditname_explainlikeimfive \u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# base_model_name = \"/projects/tir6/general/sachink/personalized-LM/2023/models/0923/sft/llama-7B_subredditname_explainlikeimfive/final_checkpoint\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# adapter_model_name = \"/projects/tir6/general/sachink/personalized-LM/2023/models/0923/dpo/llama-7B_subredditname_explainlikeimfive/final_checkpoint\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m# contextualized_all\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m# base_model_name = \"/projects/tir6/general/sachink/personalized-LM/2023/models/0923/sft/llama-7B_contextualized_all/final_checkpoint\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m# adapter_model_name = \"/projects/tir6/general/sachink/personalized-LM/2023/models/0923/dpo/llama-7B_contextualized_all/final_checkpoint\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m peft_config \u001b[39m=\u001b[39m PeftConfig\u001b[39m.\u001b[39mfrom_pretrained(adapter_model_name)\n\u001b[0;32m---> 20\u001b[0m model \u001b[39m=\u001b[39m AutoPeftModelForCausalLM\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     21\u001b[0m     base_model_name, return_dict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, torch_dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mbfloat16\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[39m# tokenizer = AutoTokenizer.from_pretrained(base_model_name)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m device\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AutoPeftModelForCausalLM' is not defined"
     ]
    }
   ],
   "source": [
    "from peft import PeftConfig, PeftModel\n",
    "\n",
    "# plain_all\n",
    "base_model_name = \"/projects/tir6/general/sachink/personalized-LM/2023/models/0923/sft/llama-7B_plain_all/final_checkpoint\"\n",
    "adapter_model_name = \"/projects/tir6/general/sachink/personalized-LM/2023/models/0923/dpo/llama-7B_plain_all/final_checkpoint\"\n",
    "# subredditname_all\n",
    "base_model_name = \"/projects/tir6/general/sachink/personalized-LM/2023/models/0923/sft/llama-7B_subredditname_all/final_checkpoint\"\n",
    "adapter_model_name = \"/projects/tir6/general/sachink/personalized-LM/2023/models/0923/dpo/llama-7B_subredditname_all/final_checkpoint\"\n",
    "# subredditname_askphysics\n",
    "# base_model_name = \"/projects/tir6/general/sachink/personalized-LM/2023/models/0923/sft/llama-7B_subredditname_askphysics/final_checkpoint\"\n",
    "# adapter_model_name = \"/projects/tir6/general/sachink/personalized-LM/2023/models/0923/dpo/llama-7B_subredditname_askphysics/final_checkpoint\"\n",
    "# subredditname_explainlikeimfive \n",
    "# base_model_name = \"/projects/tir6/general/sachink/personalized-LM/2023/models/0923/sft/llama-7B_subredditname_explainlikeimfive/final_checkpoint\"\n",
    "# adapter_model_name = \"/projects/tir6/general/sachink/personalized-LM/2023/models/0923/dpo/llama-7B_subredditname_explainlikeimfive/final_checkpoint\"\n",
    "# contextualized_all\n",
    "# base_model_name = \"/projects/tir6/general/sachink/personalized-LM/2023/models/0923/sft/llama-7B_contextualized_all/final_checkpoint\"\n",
    "# adapter_model_name = \"/projects/tir6/general/sachink/personalized-LM/2023/models/0923/dpo/llama-7B_contextualized_all/final_checkpoint\"\n",
    "peft_config = PeftConfig.from_pretrained(adapter_model_name)\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    base_model_name, return_dict=True, torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "device=0\n",
    "if not torch.cuda.is_available():\n",
    "    device=\"cpu\"  \n",
    "\n",
    "\n",
    "# # Load the Lora model\n",
    "model = PeftModel.from_pretrained(model, adapter_model_name).half().to(device)\n",
    "model.eval()\n",
    "\n",
    "# model = model.merge_and_unload()\n",
    "\n",
    "# model.save_pretrained(f\"{script_args.output_name}\")\n",
    "# tokenizer.save_pretrained(f\"{script_args.output_name}\")\n",
    "# model.push_to_hub(f\"{script_args.output_name}\", use_temp_dir=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    2,     1, 14350,   263,  2933,   304,   445,   337,  1289,   277,\n",
      "          1400,   297,   278,  1494,  1014,  1127, 27423, 29889, 27092,  1525,\n",
      "          7858,  1806, 29901, 11706,   328,  1087, 29889, 29871,    13,    13,\n",
      "         11971, 29901,  1724,   338,   278,  6437,   310,  2834, 29973, 29871,\n",
      "            13,    13,  4810,  7428,  3919, 29901, 29871],\n",
      "        [    1, 14350,   263,  2933,   304,   445,   337,  1289,   277,  1400,\n",
      "           297,   278,  1494,  1014,  1127, 27423, 29889, 27092,  1525,  7858,\n",
      "          1806, 29901, 11706,   328,  1087, 29889, 29871,    13,    13, 11971,\n",
      "         29901,  3750,   338,   321,  2806, 16397,   423, 27302, 29973, 29871,\n",
      "            13,    13,  4810,  7428,  3919, 29901, 29871]], device='cuda:0'), 'attention_mask': tensor([[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "       device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "# n = int(input(\"Output length: \" ))\n",
    "# instrtype = \"plain\"\n",
    "# domain = \"askphysics\"\n",
    "domain = \"legaladvice\"\n",
    "if instrtype == \"subredditname\":\n",
    "    instruction = f\"Write a response to this reddit post in the following subreddit. SUBREDDIT: {domain}. \\n\\n POST: \"\n",
    "elif instrtype == \"contextualized\":\n",
    "    instruction = f\"Write a response to this reddit post in the subreddit with the following description. SUBREDDIT: {SUBREDDIT2DESCRIPTION[domain]}. \\n\\n POST: \"\n",
    "else:\n",
    "    instruction = f\"Write a response to this reddit post. \\n\\n POST: \"\n",
    "\n",
    "n = 128\n",
    "\n",
    "# lines = \"\"\n",
    "# no_of_lines = 1\n",
    "# print(f\"Enter new prompt ({no_of_lines} lines): \")\n",
    "# for i in range(no_of_lines):\n",
    "#     lines += input()+\"\\n\\n\"\n",
    "lines = [\"What is the purpose of life?\", \"Why is euthanasia illegal?\"]\n",
    "    \n",
    "# input(batch)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "query_tensors = tokenizer([instruction+line+\" \\n\\n COMMENT: \" for line in lines], padding=True, return_tensors=\"pt\").to(device)\n",
    "print(query_tensors)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a response to this reddit post in the following subreddit. SUBREDDIT: legaladvice. \n",
      "\n",
      " POST: What is the purpose of life? \n",
      "\n",
      " COMMENT:  When we run out of resources, we die.  When those around us run out of resources we die.  And that's how it works for every species.  Being lazy and thoughtful enough to convince ourselves that we are a special type of life form that does not have to die off is... well, I believe it's what we call \"Arrogance\".  If we could be honest with ourselves and look at our species in the same way we look at other species in the ecosystem then we might actually make some progress on the issues we're facing.   Example: Global Warming.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# query_tensors = tokenizer.encode(lines, return_tensors=\"pt\").to(device)\n",
    "print(\"Output: \", end=\"\")\n",
    "# Get response from t5\n",
    "response_tensor = model.generate(**query_tensors, max_new_tokens=n, **generation_kwargs)\n",
    "response = tokenizer.decode(response_tensor[0], skip_special_tokens=True)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Write a response to this reddit post in the following subreddit. SUBREDDIT: legaladvice. \n",
      "\n",
      " POST: Why is euthanasia illegal? \n",
      "\n",
      " COMMENT:  Volunteer as a rescue dog handler. It’s a weird word salad way of saying you're a dog adoption social worker. Many people who can’t have dogs for whatever reason seek out rescue dogs as their companions. Some of them are great dogs. The volunteer goes out once a month to the shelters, kennels, stray pickups and all sorts of different places to see which dogs have just been saved from the street. Clean, vaccinated and ready to get the new loving home that they didn’t end up with. A lot of them are happy\n"
     ]
    }
   ],
   "source": [
    "response = tokenizer.decode(response_tensor[1], skip_special_tokens=False)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2022",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
